# 🏋️ Weight Decay (L2 Regularization)

A minimal implementation of **Weight Decay** (also known as **L2 regularization**) for neural networks using PyTorch.

## 📦 Overview

The `weight_decay` function adds a regularization term to the loss to penalize large weight values, helping to prevent overfitting and improve model generalization.

## 🚀 Features

- Pure PyTorch implementation
- Simple and customizable
- Can be integrated into any training loop
- Uses the classic L2 norm penalty: `λ * ||W||²`

## 📑 Usage Example

```