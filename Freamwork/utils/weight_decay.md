# ğŸ‹ï¸ Weight Decay (L2 Regularization)

A minimal implementation of **Weight Decay** (also known as **L2 regularization**) for neural networks using PyTorch.

## ğŸ“¦ Overview

The `weight_decay` function adds a regularization term to the loss to penalize large weight values, helping to prevent overfitting and improve model generalization.

## ğŸš€ Features

- Pure PyTorch implementation
- Simple and customizable
- Can be integrated into any training loop
- Uses the classic L2 norm penalty: `Î» * ||W||Â²`

## ğŸ“‘ Usage Example

```