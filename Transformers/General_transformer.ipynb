{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085d84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import core.optimizers as O\n",
    "import torch\n",
    "import core.losses as l\n",
    "import core.metrics as M\n",
    "from core.model_structure import Deep_learning_Model\n",
    "from transformer_operations import *\n",
    "from transformer import *\n",
    "class multilayer_transfomer(Deep_learning_Model):\n",
    "     def __init__(self, optimizer, loss,dmodel,vocab_size):\n",
    "          super().__init__(optimizer, loss)\n",
    "          self.decoders=[]\n",
    "          self.encoders=[]\n",
    "          self.weights=[]\n",
    "          self.vocab_size=vocab_size\n",
    "          self.model_dimensions=dmodel\n",
    "          self.linear=Linear(dmodel,vocab_size)\n",
    "          self.weights.extend(self.linear.weights)\n",
    "          self.embedings_layer=Embdeing_layer(self.model_dimensions)\n",
    "     def add_encoder(self,num_heads):\n",
    "          e=transformer_encoder(num_heads,self.model_dimensions)\n",
    "          self.encoders.append(e)\n",
    "          self.weights.extend(e.encoder_weights)\n",
    "     def add_decoder(self,num_heads):\n",
    "          d=transformer_decoder(num_heads,self.model_dimensions,self.vocab_size)\n",
    "          self.decoders.append(d)\n",
    "          self.weights.extend(d.decoder_weights)\n",
    "     def forward_propagation(self,source,target_embedigns):\n",
    "          x=source\n",
    "          for encoder in self.encoders:\n",
    "               x=encoder.encode(x)\n",
    "          encoder_res=x\n",
    "          for decoder in self.decoders:\n",
    "               encoder_res=decoder.multi_layer_decode(encoder_res,target_embedigns)\n",
    "          decoder_res=encoder_res\n",
    "          logits=self.linear.forward(decoder_res)\n",
    "          return logits\n",
    "     def  seq_emebidngs(self,src,tgt):\n",
    "              src_emb = self.embedings_layer.get_embedings(src)\n",
    "              tgt_emb = self.embedings_layer.get_embedings(tgt[:, :-1])\n",
    "\n",
    "              tgt_out = tgt[:, 1:]  \n",
    "              pos_src_emb=pos_encoding(src_emb,self.model_dimensions)\n",
    "              pos_tgt_emb=pos_encoding(tgt_emb,self.model_dimensions)\n",
    "              return pos_src_emb,pos_tgt_emb,tgt_out\n",
    "     \n",
    "     def train(self, epochs, x_train, y_train, targets, batch_size, learning_rate):\n",
    "          num_batches = len(x_train) // batch_size\n",
    "          for epoch in range(epochs):\n",
    "               epoch_loss = 0\n",
    "               indices = torch.randperm(len(x_train))\n",
    "               x_train, y_train, targets = x_train[indices], y_train[indices], targets[indices]\n",
    "               for i in range(num_batches):\n",
    "\n",
    "                    # 2. Forward pass (sans clonage inutile)\n",
    "                    x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                    y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "                    t_batch = targets[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "                    train_pred = self.forward_propagation(x_batch, y_batch)\n",
    "                    \n",
    "                    # 3. Compute loss\n",
    "                    loss = self.loss.compute_loss(train_pred, t_batch)\n",
    "                    \n",
    "                    # 4. Backward pass\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    \n",
    "                    # 5. Update weights\n",
    "                    self.backward_propagation(0.01,epoch+1)\n",
    "                    \n",
    "                    epoch_loss += loss.item()\n",
    "               \n",
    "               print(f'Epoch {epoch+1}, Loss: {epoch_loss/num_batches:.4f}')\n",
    "\n",
    "               \n",
    "\n",
    "    \n",
    "          \n",
    "          \n",
    "          \n",
    "     \n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da178b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1794\n",
      "Epoch 2, Loss: 0.1792\n",
      "Epoch 3, Loss: 0.1791\n",
      "Epoch 4, Loss: 0.1791\n",
      "Epoch 5, Loss: 0.1790\n",
      "Epoch 6, Loss: 0.1789\n",
      "Epoch 7, Loss: 0.1786\n",
      "Epoch 8, Loss: 0.1782\n",
      "Epoch 9, Loss: 0.1779\n",
      "Epoch 10, Loss: 0.1778\n"
     ]
    }
   ],
   "source": [
    "def generate_clean_data(batch_size, seq_len, vocab_size):\n",
    "    src = torch.randint(1, vocab_size - seq_len, (batch_size, seq_len))\n",
    "    tgt = torch.flip(src, dims=[1]) + 1\n",
    "    return src, tgt\n",
    "\n",
    "\n",
    "x,y=generate_clean_data(50,7,10)\n",
    "\n",
    "\n",
    "transfomer_model=multilayer_transfomer(\"adam\",\"Crossentropy\",10,10)\n",
    "x,y_in,y_out=transfomer_model.seq_emebidngs(x,y)\n",
    "\n",
    "transfomer_model.add_encoder(\n",
    "    1\n",
    "),\n",
    "transfomer_model.add_encoder(\n",
    "    1\n",
    ")\n",
    "transfomer_model.add_decoder(\n",
    "    1,\n",
    ")\n",
    "\n",
    "\n",
    "y_out=torch.eye(10)[y_out]\n",
    "y_out.shape\n",
    "\n",
    "\n",
    "transfomer_model.train(10,x,y_in,y_out,1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160d3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e13d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259a0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed462c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
