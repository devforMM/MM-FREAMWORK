{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866d8da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_operations import *\n",
    "from transformer import *\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from core.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac87e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 52.1319\n",
      "Epoch 1: Loss = 53.9516\n",
      "Epoch 2: Loss = 48.4636\n",
      "Epoch 3: Loss = 46.7885\n",
      "Epoch 4: Loss = 49.1238\n",
      "Epoch 5: Loss = 39.7612\n",
      "Epoch 6: Loss = 42.8764\n",
      "Epoch 7: Loss = 34.7278\n",
      "Epoch 8: Loss = 41.9942\n",
      "Epoch 9: Loss = 40.3448\n",
      "Epoch 10: Loss = 36.9893\n",
      "Epoch 11: Loss = 38.3442\n",
      "Epoch 12: Loss = 33.0752\n",
      "Epoch 13: Loss = 33.0196\n",
      "Epoch 14: Loss = 31.2774\n",
      "Epoch 15: Loss = 31.6112\n",
      "Epoch 16: Loss = 30.5426\n",
      "Epoch 17: Loss = 33.5012\n",
      "Epoch 18: Loss = 27.7305\n",
      "Epoch 19: Loss = 27.6755\n",
      "Epoch 20: Loss = 27.6033\n",
      "Epoch 21: Loss = 32.4424\n",
      "Epoch 22: Loss = 31.2129\n",
      "Epoch 23: Loss = 28.5750\n",
      "Epoch 24: Loss = 27.8751\n",
      "Epoch 25: Loss = 27.5831\n",
      "Epoch 26: Loss = 25.4702\n",
      "Epoch 27: Loss = 28.8587\n",
      "Epoch 28: Loss = 26.5015\n",
      "Epoch 29: Loss = 27.7963\n",
      "Epoch 30: Loss = 26.2349\n",
      "Epoch 31: Loss = 27.3955\n",
      "Epoch 32: Loss = 25.3113\n",
      "Epoch 33: Loss = 27.8520\n",
      "Epoch 34: Loss = 25.5043\n",
      "Epoch 35: Loss = 25.7430\n",
      "Epoch 36: Loss = 25.1322\n",
      "Epoch 37: Loss = 24.7972\n",
      "Epoch 38: Loss = 22.4735\n",
      "Epoch 39: Loss = 24.2347\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m tgt_out = tgt_out.reshape(-\u001b[32m1\u001b[39m)\n\u001b[32m     32\u001b[39m loss = criterion(out, tgt_out)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m weight \u001b[38;5;129;01min\u001b[39;00m model.w:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m weight.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\izuna\\miniconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\izuna\\miniconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\izuna\\miniconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "src_seq_len = 5\n",
    "tgt_seq_len = 6\n",
    "d_model = 512\n",
    "vocab_size = 100  \n",
    "\n",
    "e_layer = Embdeing_layer(d_model)\n",
    "model = transformer_bloc(1, d_model, vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.w.append(e_layer.embedings)\n",
    "\n",
    "def generate_clean_data(batch_size, seq_len, vocab_size):\n",
    "    src = torch.randint(1, vocab_size - seq_len, (batch_size, seq_len))\n",
    "    tgt = torch.flip(src, dims=[1]) + 1\n",
    "    return src, tgt\n",
    "\n",
    "for e in range(20):\n",
    "    src, tgt = generate_clean_data(batch_size, src_seq_len, vocab_size)\n",
    "\n",
    "    src_emb = e_layer.get_embedings(src)\n",
    "    tgt_emb = e_layer.get_embedings(tgt[:, :-1])  \n",
    "    tgt_out = tgt[:, 1:] \n",
    "\n",
    "    out = model.forward(src_emb, tgt_emb)\n",
    "    out = out.reshape(-1, vocab_size)\n",
    "    tgt_out = tgt_out.reshape(-1)\n",
    "\n",
    "    loss = criterion(out, tgt_out)\n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    for weight in model.w:\n",
    "        if weight.grad is not None:\n",
    "            with torch.no_grad():\n",
    "                weight -= 0.01 * weight.grad\n",
    "            weight.grad.zero_()  \n",
    "\n",
    "    print(f\"Epoch {e}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b65e7d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f1d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ba7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cf066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
